{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from theano import function, shared\n",
    "from theano.tensor.extra_ops import repeat, to_one_hot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the processes and variables needed for theano implementation of variational inference on the probe model\n",
    "Here I built and tested most of the machinery needed to implement variational inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "floatX = 'float32'\n",
    "sqrt_D = 8\n",
    "D = int(sqrt_D*sqrt_D)#number of pixels\n",
    "K = 2#number of objects\n",
    "N = 200#number of windows (data points)\n",
    "M = 10#number of object map samples to generate for calculating object responsibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate samples of object maps from a posterior over object maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##the variational posterior over object maps Z\n",
    "_Q_Z = T.matrix('Q_Z') ##(K,D)\n",
    "_M = T.scalar('M',dtype='int32')\n",
    "\n",
    "##a theano random number generator\n",
    "rng = MRG_RandomStreams(use_cuda = True)\n",
    "\n",
    "##sample one Z map from posterior Q_Z\n",
    "_Z_samples = rng.multinomial(pvals = repeat(_Q_Z.T,_M,axis=0)).reshape((_Q_Z.shape[1],_M,_Q_Z.shape[0])).dimshuffle((1,2,0))\n",
    "\n",
    "##functionalize\n",
    "Z_sample_func = function([_Q_Z,_M],outputs=_Z_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##to test first generate posterior from a dirichlet distribution\n",
    "alpha_0 = 1.1\n",
    "Q_Z = np.zeros((K,D), dtype=floatX)\n",
    "probs = np.random.dirichlet([alpha_0]*K,)\n",
    "for d in range(D): #np.random.permutation(D):\n",
    "    if not np.mod(d,64):\n",
    "        probs = np.random.dirichlet([alpha_0]*K,)\n",
    "    Q_Z[:,d] = probs\n",
    "print np.sum(Q_Z,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##this shows the how the crazy tensor manipulation is working\n",
    "r_shuff = function([_Q_Z, _M], outputs = repeat(_Q_Z.T,_M,axis=0).reshape((_Q_Z.shape[1],_M,_Q_Z.shape[0])).dimshuffle((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##this will help visualize\n",
    "def from_one_hot(Z,axis=0):\n",
    "    '''\n",
    "    Z ~ K x D\n",
    "    convert to 1 x D, D[i] = j, j = argmax(Z[:,i])\n",
    "    '''\n",
    "    return np.argmax(Z,axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##generate M sample maps (M x K x D)\n",
    "Z_samples = Z_sample_func(Q_Z, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Z_samples.shape\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.pcolor(from_one_hot(Z_samples[0]).reshape(np.sqrt(D),np.sqrt(D)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The object responsibility matrix (i.e., N x K matrix of object count probabilities, N = #windows, K = #possible object counts)\n",
    "TODO: THIS COMPUTATION IS WAY TOO GODDAMN SLOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##block of sampled object maps\n",
    "_Z = T.tensor3('Z') ##(M x K x D)\n",
    "\n",
    "##window index indicator (N X D)\n",
    "_W = T.matrix('windows')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expression for an (M,N) matrix of objects counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##(M x K x 1 x D)\n",
    "##         N x D\n",
    "##(M x K x N x D)  sum(D)\n",
    "##(M x K x N)      clip(0,1)\n",
    "##(M x K x N)      sum(K)\n",
    "##(M x N)\n",
    "_O_W = T.sum(_Z.dimshuffle((0,1,'x',2))*_W,axis=-1).clip(0,1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_object_count_func = function([_Z,_W], outputs=_O_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##construct some contiguous windows of varying size\n",
    "W = np.zeros((N,D),dtype=floatX)\n",
    "win_stride = np.round(D/N)\n",
    "size_factor = 2\n",
    "for n in range(N):\n",
    "    W[n,(n*win_stride):(n*win_stride+size_factor*n+1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.pcolor(W)\n",
    "plt.title('Windows')\n",
    "plt.xlabel('pixels')\n",
    "plt.ylabel('window number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = window_object_count_func(Z_samples.astype(floatX),W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.pcolor(foo)\n",
    "plt.title('object counts')\n",
    "plt.xlabel('windows')\n",
    "plt.ylabel('random samples from Q_Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##calculate rolling mean \n",
    "rolling_mean = np.zeros((M,N))\n",
    "for m in range(M-1):\n",
    "    rolling_mean[m,:] = np.mean(foo[:m+1, :], axis=0)\n",
    "\n",
    "_=plt.plot(rolling_mean[0:-1,:])\n",
    "plt.title('rolling mean of object counts for %d windows' %(N))\n",
    "plt.xlabel('number of random samples from Q_Z')\n",
    "plt.ylabel('mean object count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out one-hot encoding of the object counts (M, N, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.matrix(dtype='int32')\n",
    "object_count_one_hot_func = function([X],to_one_hot(X.flatten()-1,K).reshape((X.shape[0],X.shape[1],K)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baz = object_count_one_hot_func(foo.astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foo[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baz[:,12,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having tested the one-hot encoding, we sum across samples and divide to obtain object count probabilities (i.e., the \"object responsibility matrix\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_K = T.scalar('objects',dtype='int32')\n",
    "_R_nn = to_one_hot(_O_W.astype('int32').flatten()-1,_K).reshape((_O_W.shape[0],_O_W.shape[1],_K)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_norm_resp_func = function([_Z, _W, _K], outputs = _R_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_norm_resp = non_norm_resp_func(Z_samples.astype(floatX),W,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.pcolor(non_norm_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(non_norm_resp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##normalize\n",
    "_R = _R_nn / _R_nn.sum(axis=1).reshape((_R_nn.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##object count probabilities function\n",
    "object_count_prob_func = function([_Z, _W, _K], outputs = _R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oc = object_count_prob_func(Z_samples.astype(floatX),W,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(oc.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##some timing info--how long for one full sweep of calls for each pixel/object pair?\n",
    "Z_samples = Z_samples.astype(floatX)\n",
    "start = time()\n",
    "for d in range(D):\n",
    "    if not np.mod(d, np.round(D/12.)):\n",
    "        print '%d pixels remaining' %(D-d)\n",
    "    for k in range(K):\n",
    "        _=object_count_prob_func(Z_samples,W,K)\n",
    "end = time()-start\n",
    "print end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2*26*1000/60./60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood function and parameter updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imagery_psychophysics.src.model_z import noise_grid\n",
    "from scipy.misc import comb as nCk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counts(r,d,n):\n",
    "    return np.array([nCk(d,m)*nCk(n-d, r-m) for m in range(min(r,d)+1)])\n",
    "\n",
    "def lkhd(r,d,n,p_on,p_off):\n",
    "    probs = np.array([(1-p_on)**(d-m) * (p_on)**m * (p_off)**(r-m) * (1-p_off)**(n-d-r+m) for m in range(min(r,d)+1)])\n",
    "    #print probs\n",
    "    return counts(r,d,n).dot(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critical tensor is the likelihoods iterated over a fine grid of noise parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_dns = 25\n",
    "p_on, p_off = noise_grid(theta_dns,theta_dns)\n",
    "G = len(p_on)\n",
    "P_theta = np.zeros((G, N, K),dtype=floatX)\n",
    "r = np.random.randint(1,high=K+1, size=(N,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(p_on), np.max(p_on), np.min(p_off), np.max(p_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##fortunately we only need to generate this once.\n",
    "for g,p in enumerate(zip(p_on,p_off)):\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            P_theta[g,n,k]  = lkhd(r[n],k+1,K, p[0],p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(np.log(P_theta[-20]).T, '-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.sum(np.isfinite(np.log(P_theta)))\n",
    "print G*N*K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the simple update rule for the variational log posterior over theta (i.e., the noise parameters). It's understood that this is technically $ln[q(\\theta)] - const$\n",
    "\n",
    "Note also that we probably won't be needing the $ln[q(\\theta)]$ output, but we emit it anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_P_theta = T.tensor3('P_theta') ##(G x N x K)\n",
    "_X = T.matrix('dummy') ##N x K ~ this is a stand-in for the \"object responsibility matrix\" R\n",
    "\n",
    "##(G x N x K)\n",
    "##(    N x K)  (dot product, broadcast across G)\n",
    "##(G x 1)  --> because we don't do vectors we reshape to make output 2Dimensional (G x 1)\n",
    "_lnQ_theta = T.tensordot(T.log(_P_theta),_X, axes=[[1,2], [0,1]],).reshape((_P_theta.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lnQ_theta_update_func = function([_P_theta, _X], outputs = _lnQ_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lnQ_theta_update_func(np.random.random((G,N,K)).astype(floatX), np.random.random((N,K)).astype(floatX)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select the best noise params\n",
    "_P_star = _P_theta[T.argmax(_lnQ_theta),:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_star_update_func = function([_P_theta, _X], outputs = _P_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = P_star_update_func(P_theta, np.random.random((N,K)).astype(floatX))\n",
    "print foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##put the lnQ_theta and lnP_star updates into same handy function\n",
    "theta_update_func = function([_P_theta,_X], outputs = [_lnQ_theta, _P_star])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lnQ_theta, P_star = theta_update_func(P_theta, np.random.random((N,K)).astype(floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print lnQ_theta.shape ##(G,)\n",
    "print P_star.shape  ##(N , K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior over object maps\n",
    "Main quantity of interest here is $\\mathbb{E}[ln[\\pi]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_alpha_0 = T.scalar('alpha_0')\n",
    "_q_Z = T.matrix('q_Z')  ##K x 1, this is result of summing over pixels in Q_Z matrix\n",
    "\n",
    "_alpha = _q_Z + _alpha_0 ##broadcasts the scalar _alpha_0 across K\n",
    "\n",
    "_Eln_pi = T.psi(_alpha) - T.psi(_alpha.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Eln_pi_update_func = function([_q_Z, _alpha_0], outputs = _Eln_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_0 = 1.1\n",
    "q_Z = np.random.dirichlet([alpha_0]*K,).astype(floatX)[:,np.newaxis] ##a fake q_Z\n",
    "\n",
    "Eln_pi = Eln_pi_update_func(q_Z, alpha_0)\n",
    "plt.plot(Eln_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Eln_pi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update variational posterior for object maps\n",
    "\n",
    "This will be the only update that returns a normalized variational posterior.\n",
    "Uses the responsibility matrices above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_R_full = T.tensor4('responsibility_tensor') ##K x D x N x K\n",
    "_lnP_star = T.matrix('lnP_star') ##N x K\n",
    "_V = T.matrix('prior_penalties') ## K x D\n",
    "\n",
    "##K x D x N x K\n",
    "##        N x K (dot)\n",
    "##K x D         (add V)\n",
    "##K x D         exp\n",
    "##K x D         normalize\n",
    "\n",
    "_lnQ_Z_nn = T.tensordot(_R_full, _lnP_star, [[2,3], [0,1]])+_V\n",
    "_Q_Z_nn = T.exp(_lnQ_Z_nn-T.max(_lnQ_Z_nn,axis=0)) \n",
    "_Q_Z = _Q_Z_nn / _Q_Z_nn.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.exp(-88, dtype=floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.exp(-500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q_Z_update_func = function([_R_full, _lnP_star, _V], outputs=[_Q_Z, _Q_Z_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##some timing info--how long for one full sweep of calls for each pixel/object pair?\n",
    "R_full = np.zeros((K,D,N,K),dtype=floatX)\n",
    "lnP_star = np.log(P_star).astype(floatX)\n",
    "V = np.random.random(size=(K,D)).astype(floatX)+alpha_0\n",
    "start = time()\n",
    "for k in range(K):\n",
    "    print '%d objects remaining' %(K-k)\n",
    "    for d in range(D):\n",
    "        R_full[k,d,:,:] =object_count_prob_func(Z_samples,W,K)\n",
    "Q_Z_new, foo = Q_Z_update_func(R_full, lnP_star, V)\n",
    "end = time()-start\n",
    "print end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = _lnQ_Z_nn.eval({_R_full: R_full, _lnP_star: lnP_star, _V: V})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baz = np.exp((foo-np.max(foo,axis=0)))\n",
    "print baz\n",
    "# print baz / baz.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Q_Z_new.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.pcolor(Q_Z_new[1,:].reshape(sqrt_D,sqrt_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expressions for the ELBO\n",
    "I suppose this is an approximate ELBO since we are using a $max \\approx expectation$ approximation for $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_Eln_pi = T.matrix('Eln_pi')  ##K x 1\n",
    "_Q_Z = T.matrix('Q_Z')        ##K x D\n",
    "_lnQ_theta = T.matrix('lnQ_theta') ##G x 1\n",
    "\n",
    "_q_Z = _Q_Z.sum(axis=1,keepdims=True) #K x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros((K,D)).sum(axis=1,keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_prior_entropy = -(T.tensordot(_q_Z-1, _Eln_pi)-(T.gammaln(_q_Z.sum()) - T.sum(T.gammaln(_q_Z))))\n",
    "_posterior_entropy = -T.tensordot(_Q_Z, T.log(_Q_Z)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print _prior_entropy.eval({_Q_Z : Q_Z_new, _Eln_pi : Eln_pi})\n",
    "print _posterior_entropy.eval({_Q_Z : Q_Z_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ELBO = _lnQ_theta.max()  - _posterior_entropy - _prior_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ELBO_update_func = function([_Eln_pi, _Q_Z, _lnQ_theta], outputs=_ELBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Eln_pi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lnQ_theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q_Z_new.sum(axis=1,keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ELBO = ELBO_update_func(Eln_pi, Q_Z_new, lnQ_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ELBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well. The sign is right. We'll see if it makes any sense..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imagery_psychophysics.src.stirling_maps import sparse_point_maps as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##first some more sensical windows\n",
    "scales = np.array([2, 4, 6, 8])\n",
    "stride = 2\n",
    "sizes = scales/2\n",
    "Windows = []\n",
    "for sz in sizes:\n",
    "    scale_count = 0\n",
    "    for rows in np.arange(sz,sqrt_D,stride,dtype=int, ):\n",
    "        for cols in np.arange(sz,sqrt_D,stride,dtype=int):\n",
    "            one_win = np.zeros((sqrt_D,sqrt_D),dtype=floatX)\n",
    "            one_win[(rows-sz):(rows+sz), (cols-sz):(cols+sz)]=1\n",
    "            Windows.append(one_win)\n",
    "            scale_count +=1\n",
    "    print scale_count\n",
    "\n",
    "\n",
    "N = len(Windows)\n",
    "npairs = 1000\n",
    "W = np.zeros((N+npairs,D),dtype=floatX)\n",
    "for n in range(N):\n",
    "    W[n,:] = Windows.pop().ravel()\n",
    "\n",
    "for n in range(N,N+npairs):\n",
    "    rand_pairs = np.random.permutation(N)[:2]\n",
    "    W[n,:] = np.clip(W[rand_pairs[0],:]+W[rand_pairs[1],:], 0, 1)\n",
    "    \n",
    "N = W.shape[0]\n",
    "print N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##construct a test object map\n",
    "test_object_map = spm(3,3,sqrt_D,cluster_pref = 'random',number_of_clusters = K)\n",
    "test_object_map.scatter()\n",
    "test_object_map = np.squeeze(test_object_map.nn_interpolation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_object_map, cmap='Dark2')\n",
    "plt.imshow(W[-1].reshape((sqrt_D,sqrt_D)).astype('uint8')*255, interpolation='nearest', alpha = .5, cmap=plt.cm.gray, clim=[0,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##convert to one_hot encoding\n",
    "test_Z = np.eye(K)[test_object_map.ravel()-1].T  ##K x D\n",
    "d = 5\n",
    "print test_object_map[d,d]\n",
    "print test_Z.reshape((K,sqrt_D,sqrt_D))[:,d,d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##get true object counts for each window\n",
    "object_counts = np.sum(test_Z[:,np.newaxis,:]*W,axis=-1).clip(0,1).sum(axis=0).astype('int')\n",
    "object_counts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "object_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##generate some fake responses using fixed theta parameters\n",
    "p_on = 0.99\n",
    "p_off = 0.01\n",
    "r = np.zeros(object_counts.shape[0], dtype = 'int')\n",
    "for ii,o in enumerate(object_counts):\n",
    "    resp_dist = np.zeros(K)\n",
    "    for k in range(K):\n",
    "        resp_dist[k] = lkhd(k+1,o,K,p_on,p_off)\n",
    "        r[ii]=np.argmax(np.random.multinomial(1,resp_dist))+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.abs(r-object_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.abs(r-object_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete loop for variational dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##to test first generate posterior from a dirichlet distribution\n",
    "\n",
    "alpha_0 = 1.1\n",
    "\n",
    "theta_plus, theta_minus = .99, .01\n",
    "\n",
    "def init_Q():\n",
    "    Q_Z = np.zeros((K,D), dtype=floatX)\n",
    "    probs = np.random.dirichlet([alpha_0]*K,)\n",
    "    for d in range(D): #np.random.permutation(D):\n",
    "        if not np.mod(d,64):\n",
    "            probs = np.random.dirichlet([alpha_0]*K,)\n",
    "        Q_Z[:,d] = probs\n",
    "    return Q_Z\n",
    "\n",
    "def init_Eln_pi():\n",
    "    q_Z = np.random.dirichlet([2.1]*K,).astype(floatX).reshape((K,1)) ##a fake q_Z\n",
    "    Eln_pi = Eln_pi_update_func(q_Z, alpha_0)\n",
    "    return Eln_pi\n",
    "\n",
    "def init_P_star():\n",
    "    P_theta = np.zeros((N,K),dtype=floatX)\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            P_theta[n,k]  = lkhd(r[n],k+1,K, theta_plus,theta_minus)\n",
    "    return P_theta\n",
    "\n",
    "\n",
    "R_full = np.zeros((K,D,N,K),dtype=floatX)\n",
    "V = np.zeros((K,D),dtype=floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems this posterior update is wrong. It's not coordinate ascent. It ascends multiple coordinates at once. Apparently there is not guarantee that this update rule will converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p_Z(lnP_star, Eln_pi): \n",
    "    for d in range(D):\n",
    "        if not np.mod(d, np.round(D/12.)):\n",
    "            print '%d pixels remaining' %(D-d)\n",
    "        for k in range(K):\n",
    "            Z = Z_samples.copy()\n",
    "            Z[:,:,d] = 0.\n",
    "            Z[:,k, d] = 1.\n",
    "            R_full[k,d,:,:] =object_count_prob_func(Z,W,K).astype(floatX)\n",
    "            V[k,d] = np.dot(Z[0,:,d], Eln_pi)\n",
    "    Q_Z_new, Q_Z_new_nn = Q_Z_update_func(R_full, lnP_star, V)\n",
    "    return Q_Z_new, Q_Z_new_nn, V, R_full\n",
    "\n",
    "\n",
    "\n",
    "Q_Z = init_Q()\n",
    "Eln_pi = init_Eln_pi()\n",
    "P_star = init_P_star()\n",
    "\n",
    "ELBO = -np.inf\n",
    "delta_ELBO = np.inf\n",
    "\n",
    "P_theta = np.zeros((1,N,K), dtype=floatX)\n",
    "for n in range(N):\n",
    "    for k in range(K):\n",
    "        P_theta[0,n,k]  = lkhd(r[n],k+1,K, theta_plus,theta_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "max_T = 300\n",
    "ELBO = np.zeros(max_T)\n",
    "M = 200\n",
    "while (delta_ELBO > 0) and (t < max_T):\n",
    "    print 'iteration: %d' %(t,)\n",
    "    \n",
    "    Z_samples = Z_sample_func(Q_Z, M).astype(floatX)\n",
    "    lnP_star = np.log(P_star).astype(floatX)\n",
    "    Q_Z, Q_Z_nn,V,R_full = p_Z(lnP_star, Eln_pi.astype(floatX))\n",
    "    print _lnQ_Z_nn.eval({_R_full: R_full, _lnP_star: lnP_star, _V: V})\n",
    "#     print Eln_pi\n",
    "#     if not np.all(np.isfinite(Q_Z)):\n",
    "#         print _lnQ_Z_nn.eval({_R_full: R_full, _lnP_star: lnP_star, _V: V})\n",
    "#         print Q_Z_nn\n",
    "#         assert False\n",
    "    Z_new = Z_sample_func(Q_Z, M).astype(floatX)\n",
    "    R = object_count_prob_func(Z_new, W, K)\n",
    "    lnQ_theta, P_star = theta_update_func(P_theta, R)\n",
    "    Eln_pi = Eln_pi_update_func(Q_Z.sum(axis=1,keepdims=True), alpha_0)\n",
    "    print Eln_pi\n",
    "    ELBO[t] = ELBO_update_func(Eln_pi, Q_Z, lnQ_theta)\n",
    "    print '============ELBO: %f' %(ELBO[t])\n",
    "    print 'prior entropy: %f' %(_prior_entropy.eval({_Q_Z : Q_Z, _Eln_pi : Eln_pi}))\n",
    "    print 'posterior entropy: %f' %(_posterior_entropy.eval({_Q_Z : Q_Z}))\n",
    "    print 'goodness of fit: %f' %(np.max(lnQ_theta))\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(lnP_star.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ELBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "images = [Q_Z[0,:].reshape((sqrt_D,sqrt_D)), Q_Z[1,:].reshape((sqrt_D,sqrt_D))]\n",
    "\n",
    "##view: construct an image grid\n",
    "fig = plt.figure(1, (15,5))\n",
    "grid = ImageGrid(fig, 111, # similar to subplot(111)\n",
    "                nrows_ncols = (1, 3), # creates 2x2 grid of axes\n",
    "                axes_pad=0.5, # pad between axes in inch.\n",
    "                cbar_mode = 'each',\n",
    "                cbar_pad = .05\n",
    "                )\n",
    "im = grid[0].imshow(test_object_map,cmap='Dark2')\n",
    "grid[0].cax.colorbar(im)\n",
    "for kk in range(1,K+1):\n",
    "    im = grid[kk].imshow(images.pop(0), cmap='hot', clim=[0,1])\n",
    "    grid[kk].cax.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
