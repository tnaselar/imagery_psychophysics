{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagery_psychophysics.src.variational as very\n",
    "from imagery_psychophysics.src.stirling_maps import stirling_num_of_2nd_kind as snk\n",
    "from imagery_psychophysics.src.stirling_maps import stirling_partitions\n",
    "from skimage.morphology import binary_dilation, binary_erosion\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "from PIL.Image import open as open_image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDict = dict()\n",
    "experiment_df = open_imagery_probe_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, subject_group in experiment_df.groupby('subj'):\n",
    "    resultsDict[subject] = dict()\n",
    "    for state, state_group in subject_group.groupby('state'):\n",
    "        resultsDict[subject][state] = dict()\n",
    "        for targetImageName, target_group in state_group.groupby('image'):\n",
    "            ##get data\n",
    "            windows, resp, _, targetObjectMap,targetImage = open_imagery_probe_data(subject, state, targetImageName)\n",
    "            \n",
    "            \n",
    "            ##==========construct model random variables\n",
    "            ##number of objects\n",
    "            nObj = numObjects()\n",
    "\n",
    "            ##dispersion on category prior: here we set a hyperprior\n",
    "            pDisp = priorDispersion()\n",
    "            dispersion = 1.0\n",
    "            pDisp.set_value(dispersion)\n",
    "\n",
    "            ##resolution of object map Z\n",
    "            nPixels = numPixels()\n",
    "\n",
    "            ##category prior and object map\n",
    "            catProb = categoryProbs(nObj,pDisp)\n",
    "            Z = latentObjMap(catProb,nPixels)\n",
    "\n",
    "            ##noise params\n",
    "            nP = noiseParams()\n",
    "\n",
    "            ##windows: we change their shape a little to make them easier to work with\n",
    "            desiredWindowShape = (375,600)\n",
    "            workingScale = 5\n",
    "            w = probes()\n",
    "            resolutions, workingResolution = w.resolve(desiredWindowShape, workingScale)\n",
    "            w.set_value(w.reshape(windows, workingResolution),flatten=True)\n",
    "            print 'working resolution is (%d, %d)' %(workingResolution[0], workingResolution[1])\n",
    "\n",
    "\n",
    "            ##response object\n",
    "            r = responses(Z,nP)\n",
    "\n",
    "            ##fake data\n",
    "            r.set_values(windows=w)\n",
    "\n",
    "            r.set_values(data=resp)\n",
    "\n",
    "            print 'total observations: %d' %(r.N)\n",
    "\n",
    "            tMap = target_image()\n",
    "            targetObjectMap_test, targetImage_test = tMap.reshape(targetObjectMap,workingResolution,targetImage=targetImage)\n",
    "            tMap.set_values(targetObjectMap_test, targetImage_test)\n",
    "            ##=============\n",
    "            \n",
    "            ##instantiate the variational inferences we want to perform\n",
    "            iqZ = inferQZ()\n",
    "            iqPi = inferQPi()\n",
    "\n",
    "            ##...and the parameter optimizations (point-estimate) we want\n",
    "            oNP = optimizeNoiseParams()\n",
    "\n",
    "            ##variational inference combines them all together\n",
    "            vi = VI(r, iqZ,oNP, iqPi)\n",
    "\n",
    "            ### Run variational inference\n",
    "\n",
    "            ##inference algorithm parameters\n",
    "            initialNoisinessOfZ = 0.2\n",
    "            pOn_init, pOff_init = .8, 0.2\n",
    "            densityOfNoiseParamGrid = 50\n",
    "            numStarterMaps = 20\n",
    "            numSamplesForComputingObjectCountProbs = 4\n",
    "            maxNumIterations = 50\n",
    "            trainTestSplit = 0.8\n",
    "            trainRegSplit = .8\n",
    "            pixelNumOverMin = 2\n",
    "            objectNumOverMin = 2\n",
    "\n",
    "            print '=========================(subject, state, target) = (%s, %s, %s) ====' %(subject, state, targetImageName)\n",
    "            bestModel,_ = vi.run_VI(initialNoisinessOfZ, \\\n",
    "                                 pOn_init, pOff_init, \\\n",
    "                                 densityOfNoiseParamGrid, \\\n",
    "                                 numStarterMaps, \\\n",
    "                                 numSamplesForComputingObjectCountProbs, \\\n",
    "                                 maxNumIterations, \\\n",
    "                                 trainTestSplit, trainRegSplit, \\\n",
    "                                 optimizeHyperParams=False)\n",
    "\n",
    "            resultsDict[subject][state][targetImageName]= copy.deepcopy(bestModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
